================================================================================
AN√ÅLISE DE MELHORIAS DO SISTEMA - JURIS IA CORE V1
================================================================================

DATA: 2025-12-17
OBJETIVO: Identificar gaps e propor melhorias t√©cnicas para aumentar precis√£o,
          efic√°cia pedag√≥gica e robustez do sistema

================================================================================
1. AN√ÅLISE DO ESTADO ATUAL
================================================================================

1.1. O QUE J√Å FUNCIONA BEM
---------------------------

‚úÖ Arquitetura de dados robusta (PostgreSQL + pgvector)
‚úÖ Sistema de autentica√ß√£o completo (JWT + roles)
‚úÖ Billing e subscription implementado (Stripe)
‚úÖ Feature flags para controle de rollout
‚úÖ Compliance LGPD completo
‚úÖ M√©tricas de uso e sess√£o
‚úÖ Ingest√£o de dados em lote com idempot√™ncia
‚úÖ Isolamento de gabarito (role-based)
‚úÖ Classifica√ß√£o de erros (6 tipos)

1.2. GAPS CR√çTICOS IDENTIFICADOS
---------------------------------

‚ùå FALTA: Sistema de busca sem√¢ntica (embeddings n√£o gerados)
‚ùå FALTA: LLM integration para explica√ß√µes personalizadas
‚ùå FALTA: Sistema de spaced repetition (revis√£o espa√ßada)
‚ùå FALTA: Adaptive learning (ajuste de dificuldade)
‚ùå FALTA: Caching de queries frequentes
‚ùå FALTA: Sistema de recomenda√ß√£o de estudo
‚ùå FALTA: Detec√ß√£o de padr√µes de erro recorrentes
‚ùå FALTA: Feedback pedag√≥gico imediato
‚ùå FALTA: Gamification (motiva√ß√£o do usu√°rio)
‚ùå FALTA: Analytics preditivos (probabilidade de aprova√ß√£o)


================================================================================
2. MELHORIAS DE PRECIS√ÉO E EFIC√ÅCIA PEDAG√ìGICA
================================================================================

2.1. SISTEMA DE EMBEDDINGS E BUSCA SEM√ÇNTICA
---------------------------------------------

PROBLEMA ATUAL:
  - Embeddings existem na tabela (coluna embedding) mas n√£o s√£o gerados
  - Busca por quest√µes √© apenas por filtros simples (√°rea, dificuldade)
  - N√£o h√° recomenda√ß√£o de quest√µes similares
  - N√£o h√° agrupamento por conceitos relacionados

SOLU√á√ÉO PROPOSTA:

[A] GERA√á√ÉO DE EMBEDDINGS

Criar: scripts/gerar_embeddings.py

  from openai import OpenAI
  import numpy as np
  from sqlalchemy import text
  from database.connection import DatabaseConnection

  class EmbeddingGenerator:
      def __init__(self):
          self.client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
          self.db = DatabaseConnection()
          self.model = "text-embedding-3-large"  # 3072 dimens√µes

      def gerar_embedding_questao(self, questao_id: UUID):
          """Gera embedding para quest√£o."""
          with self.db.get_session() as session:
              # Buscar quest√£o
              result = session.execute(
                  text("""
                      SELECT enunciado, alternativas::text
                      FROM questao_oab
                      WHERE id = :id
                  """),
                  {"id": questao_id}
              ).fetchone()

              if not result:
                  return

              enunciado, alternativas = result

              # Concatenar enunciado + alternativas
              texto_completo = f"{enunciado}\n\n{alternativas}"

              # Gerar embedding via OpenAI
              response = self.client.embeddings.create(
                  model=self.model,
                  input=texto_completo
              )

              embedding = response.data[0].embedding

              # Salvar embedding
              session.execute(
                  text("""
                      UPDATE questao_oab
                      SET embedding = :embedding::vector
                      WHERE id = :id
                  """),
                  {
                      "id": questao_id,
                      "embedding": embedding
                  }
              )
              session.commit()

      def gerar_embedding_norma(self, norma_id: UUID):
          """Gera embedding para norma."""
          # Similar ao de quest√£o
          pass

      def gerar_todos_embeddings(self):
          """Gera embeddings para todos os registros."""
          # Processar em batches de 100
          pass

Execu√ß√£o:
  python scripts/gerar_embeddings.py --batch-size 100

CUSTO ESTIMADO (OpenAI):
  - text-embedding-3-large: $0.00013 / 1K tokens
  - 3.900 normas √ó ~200 tokens = 780K tokens = $0.10
  - 500 quest√µes √ó ~300 tokens = 150K tokens = $0.02
  - TOTAL: ~$0.12 (uma vez)


[B] BUSCA SEM√ÇNTICA

Adicionar ao question_engine_db.py:

  def buscar_questoes_similares(
      self,
      questao_id: UUID,
      limite: int = 5
  ) -> List[Dict]:
      """
      Busca quest√µes semanticamente similares.

      Args:
          questao_id: ID da quest√£o de refer√™ncia
          limite: N√∫mero de quest√µes similares

      Returns:
          Lista de quest√µes similares ordenadas por similaridade
      """
      with self.db.get_session() as session:
          # Buscar embedding da quest√£o de refer√™ncia
          result = session.execute(
              text("SELECT embedding FROM questao_oab WHERE id = :id"),
              {"id": questao_id}
          ).fetchone()

          if not result or not result[0]:
              return []

          embedding_ref = result[0]

          # Buscar quest√µes similares usando cosine similarity
          results = session.execute(
              text("""
                  SELECT
                      id,
                      numero_questao,
                      area,
                      enunciado,
                      dificuldade_real,
                      1 - (embedding <=> :embedding::vector) as similaridade
                  FROM questao_oab
                  WHERE id != :questao_id
                    AND embedding IS NOT NULL
                  ORDER BY embedding <=> :embedding::vector
                  LIMIT :limite
              """),
              {
                  "questao_id": questao_id,
                  "embedding": embedding_ref,
                  "limite": limite
              }
          ).fetchall()

          return [
              {
                  "id": r[0],
                  "numero_questao": r[1],
                  "area": r[2],
                  "enunciado": r[3][:200] + "...",
                  "dificuldade_real": float(r[4]),
                  "similaridade": float(r[5])
              }
              for r in results
          ]

USO PEDAG√ìGICO:
  - Ap√≥s responder uma quest√£o, sugerir quest√µes similares
  - Refor√ßar conceitos relacionados
  - Identificar padr√µes de erro em temas similares


[C] CRIAR √çNDICE IVFFLAT (OTIMIZA√á√ÉO)

Migration adicional:

  -- √çndice para busca vetorial r√°pida
  CREATE INDEX idx_questao_oab_embedding
  ON questao_oab
  USING ivfflat (embedding vector_cosine_ops)
  WITH (lists = 100);

  CREATE INDEX idx_norma_legal_embedding
  ON norma_legal
  USING ivfflat (embedding vector_cosine_ops)
  WITH (lists = 100);

GANHO DE PERFORMANCE:
  - Busca em 10.000 quest√µes: 5000ms ‚Üí 50ms (100x mais r√°pido)


2.2. INTEGRA√á√ÉO COM LLM PARA EXPLICA√á√ïES
-----------------------------------------

PROBLEMA ATUAL:
  - N√£o h√° explica√ß√£o do porqu√™ de cada erro
  - Feedback gen√©rico ("Voc√™ errou")
  - Usu√°rio n√£o aprende com o erro

SOLU√á√ÉO PROPOSTA:

[A] ENGINE DE EXPLICA√á√ïES

Adicionar ao explanation_engine_db.py:

  def gerar_explicacao_erro(
      self,
      questao_id: UUID,
      alternativa_escolhida: str,
      alternativa_correta: str,
      tipo_erro: str
  ) -> str:
      """
      Gera explica√ß√£o personalizada do erro usando LLM.

      Args:
          questao_id: ID da quest√£o
          alternativa_escolhida: Letra escolhida
          alternativa_correta: Letra correta
          tipo_erro: Tipo de erro cometido

      Returns:
          Explica√ß√£o pedag√≥gica do erro
      """
      # Buscar quest√£o completa
      questao = self._buscar_questao_completa(questao_id)

      # Buscar normas relacionadas
      normas = self._buscar_normas_relacionadas(questao_id)

      # Construir prompt para LLM
      prompt = f"""Voc√™ √© um professor especialista em Direito para prepara√ß√£o OAB.

Um aluno respondeu a seguinte quest√£o:

ENUNCIADO:
{questao['enunciado']}

ALTERNATIVAS:
{self._formatar_alternativas(questao['alternativas'])}

O aluno escolheu a alternativa {alternativa_escolhida}, mas a resposta correta √© {alternativa_correta}.

Tipo de erro: {tipo_erro}

NORMAS RELACIONADAS:
{self._formatar_normas(normas)}

Gere uma explica√ß√£o pedag√≥gica em at√© 150 palavras que:
1. Explique por que a alternativa {alternativa_escolhida} est√° INCORRETA
2. Explique por que a alternativa {alternativa_correta} est√° CORRETA
3. Reforce o conceito jur√≠dico central
4. Cite a norma aplic√°vel

Seja claro, objetivo e educativo. N√£o seja condescendente."""

      # Chamar LLM
      from openai import OpenAI
      client = OpenAI()

      response = client.chat.completions.create(
          model="gpt-4o-mini",  # Mais barato para explica√ß√µes
          messages=[
              {"role": "system", "content": "Voc√™ √© um professor de Direito especializado em prepara√ß√£o para OAB."},
              {"role": "user", "content": prompt}
          ],
          max_tokens=300,
          temperature=0.7
      )

      explicacao = response.choices[0].message.content

      # Salvar explica√ß√£o no banco para cache
      self._salvar_explicacao_cache(
          questao_id,
          alternativa_escolhida,
          explicacao
      )

      return explicacao

CUSTO ESTIMADO:
  - gpt-4o-mini: $0.15 / 1M input tokens, $0.60 / 1M output tokens
  - Por explica√ß√£o: ~500 tokens input + ~200 tokens output = $0.0002
  - 1000 explica√ß√µes/dia = $0.20/dia = $6/m√™s
  - Com cache: ~50% reutiliza√ß√£o = $3/m√™s

TABELA DE CACHE:

  CREATE TABLE explicacao_cache (
      id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
      questao_id UUID NOT NULL REFERENCES questao_oab(id),
      alternativa_erro VARCHAR(1) NOT NULL,
      explicacao TEXT NOT NULL,
      created_at TIMESTAMP DEFAULT NOW(),
      hits INTEGER DEFAULT 0,  -- Quantas vezes foi reutilizada
      UNIQUE(questao_id, alternativa_erro)
  );

  CREATE INDEX idx_explicacao_cache_questao ON explicacao_cache(questao_id);


[B] FEEDBACK IMEDIATO

Modificar fluxo de resposta:

  POST /questao/responder
  {
    "questao_id": "uuid",
    "alternativa_escolhida": "B"
  }

  RESPONSE:
  {
    "correto": false,
    "alternativa_correta": "C",
    "tipo_erro": "normativo",
    "explicacao": "Voc√™ escolheu a alternativa B, que menciona o prazo de 15 dias,
                   mas segundo o Art. 5¬∫, LXXVIII da CF/88, o prazo razo√°vel para
                   habeas corpus √© de 72 horas conforme jurisprud√™ncia consolidada
                   do STF. A alternativa correta √© C...",
    "normas_relacionadas": [
      {
        "codigo": "CF_ART_5_LXXVIII",
        "texto": "a todos, no √¢mbito judicial e administrativo..."
      }
    ],
    "questoes_similares": [...]
  }


2.3. SISTEMA DE SPACED REPETITION
----------------------------------

PROBLEMA ATUAL:
  - Usu√°rio responde quest√£o uma vez e nunca mais revisa
  - Esquecimento natural n√£o √© combatido
  - Conhecimento n√£o √© consolidado

SOLU√á√ÉO PROPOSTA: Algoritmo SM-2 (SuperMemo 2)

[A] TABELA DE REVIS√ÉO

Migration:

  CREATE TABLE revisao_espacada (
      id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
      usuario_id UUID NOT NULL REFERENCES usuario(id),
      questao_id UUID NOT NULL REFERENCES questao_oab(id),

      -- Algoritmo SM-2
      facilidade DECIMAL(3,2) DEFAULT 2.5,  -- 1.3 a 2.5
      intervalo_dias INTEGER DEFAULT 1,
      repeticoes INTEGER DEFAULT 0,

      -- Estado
      proxima_revisao DATE NOT NULL,
      ultima_revisao DATE,
      status VARCHAR(20) DEFAULT 'aprendendo',  -- aprendendo, revisando, dominado

      -- Hist√≥rico
      total_revisoes INTEGER DEFAULT 0,
      acertos_consecutivos INTEGER DEFAULT 0,

      -- Auditoria
      created_at TIMESTAMP DEFAULT NOW(),
      updated_at TIMESTAMP DEFAULT NOW(),

      UNIQUE(usuario_id, questao_id)
  );

  CREATE INDEX idx_revisao_espacada_usuario ON revisao_espacada(usuario_id);
  CREATE INDEX idx_revisao_espacada_proxima ON revisao_espacada(proxima_revisao);


[B] ALGORITMO SM-2

Adicionar ao question_engine_db.py:

  def registrar_revisao(
      self,
      usuario_id: UUID,
      questao_id: UUID,
      acertou: bool
  ):
      """
      Registra revis√£o e calcula pr√≥xima data usando SM-2.

      Algoritmo SM-2:
      - Se errou: reinicia (intervalo = 1 dia)
      - Se acertou:
        * 1¬™ vez: pr√≥xima em 1 dia
        * 2¬™ vez: pr√≥xima em 6 dias
        * 3¬™+ vez: intervalo *= facilidade

      Facilidade ajustada com base na performance:
      - Acertou f√°cil: facilidade aumenta
      - Acertou dif√≠cil: facilidade mant√©m
      - Errou: facilidade diminui
      """
      with self.db.get_session() as session:
          # Buscar registro ou criar
          result = session.execute(
              text("""
                  SELECT facilidade, intervalo_dias, repeticoes, acertos_consecutivos
                  FROM revisao_espacada
                  WHERE usuario_id = :usuario_id AND questao_id = :questao_id
              """),
              {"usuario_id": usuario_id, "questao_id": questao_id}
          ).fetchone()

          if result:
              facilidade, intervalo, repeticoes, acertos_consec = result
          else:
              facilidade, intervalo, repeticoes, acertos_consec = 2.5, 1, 0, 0

          # Aplicar SM-2
          if acertou:
              acertos_consec += 1

              if repeticoes == 0:
                  intervalo = 1
              elif repeticoes == 1:
                  intervalo = 6
              else:
                  intervalo = int(intervalo * facilidade)

              repeticoes += 1

              # Ajustar facilidade (aumenta se acertou)
              facilidade = min(2.5, facilidade + 0.1)

              status = 'dominado' if acertos_consec >= 3 else 'revisando'

          else:
              # Errou: reinicia
              intervalo = 1
              repeticoes = 0
              acertos_consec = 0

              # Diminui facilidade (fica mais dif√≠cil)
              facilidade = max(1.3, facilidade - 0.2)

              status = 'aprendendo'

          # Calcular pr√≥xima revis√£o
          from datetime import date, timedelta
          proxima_revisao = date.today() + timedelta(days=intervalo)

          # Salvar
          session.execute(
              text("""
                  INSERT INTO revisao_espacada (
                      id, usuario_id, questao_id, facilidade, intervalo_dias,
                      repeticoes, proxima_revisao, ultima_revisao, status,
                      total_revisoes, acertos_consecutivos
                  ) VALUES (
                      :id, :usuario_id, :questao_id, :facilidade, :intervalo,
                      :repeticoes, :proxima, :ultima, :status, :total, :acertos
                  )
                  ON CONFLICT (usuario_id, questao_id)
                  DO UPDATE SET
                      facilidade = EXCLUDED.facilidade,
                      intervalo_dias = EXCLUDED.intervalo_dias,
                      repeticoes = EXCLUDED.repeticoes,
                      proxima_revisao = EXCLUDED.proxima_revisao,
                      ultima_revisao = EXCLUDED.ultima_revisao,
                      status = EXCLUDED.status,
                      total_revisoes = revisao_espacada.total_revisoes + 1,
                      acertos_consecutivos = EXCLUDED.acertos_consecutivos
              """),
              {
                  "id": uuid4(),
                  "usuario_id": usuario_id,
                  "questao_id": questao_id,
                  "facilidade": facilidade,
                  "intervalo": intervalo,
                  "repeticoes": repeticoes,
                  "proxima": proxima_revisao,
                  "ultima": date.today(),
                  "status": status,
                  "total": 1,
                  "acertos": acertos_consec
              }
          )
          session.commit()


[C] ENDPOINT DE REVIS√ïES PENDENTES

  GET /revisoes/pendentes

  RESPONSE:
  {
    "total_pendentes": 15,
    "revisoes_hoje": [
      {
        "questao_id": "uuid",
        "numero_questao": "OAB_XXX_1P_Q05",
        "area": "Direito Penal",
        "dias_desde_ultima": 6,
        "status": "revisando",
        "acertos_consecutivos": 1
      }
    ],
    "proximas_revisoes": {
      "amanha": 5,
      "proximos_7_dias": 23
    }
  }

GANHO PEDAG√ìGICO:
  - Reten√ß√£o de longo prazo aumenta de ~30% para ~80%
  - Consolida√ß√£o de conhecimento
  - Combate √† curva do esquecimento


2.4. ADAPTIVE LEARNING (AJUSTE DE DIFICULDADE)
-----------------------------------------------

PROBLEMA ATUAL:
  - Usu√°rio sempre recebe quest√µes aleat√≥rias
  - N√£o h√° adapta√ß√£o ao n√≠vel de conhecimento
  - Usu√°rio pode ficar frustrado (muito dif√≠cil) ou entediado (muito f√°cil)

SOLU√á√ÉO PROPOSTA: Sistema de dificuldade adaptativa

[A] CALCULAR N√çVEL DO USU√ÅRIO

  def calcular_nivel_usuario(self, usuario_id: UUID) -> float:
      """
      Calcula n√≠vel atual do usu√°rio (0.0 a 1.0).

      Baseado em:
      - Taxa de acerto recente (√∫ltimas 20 quest√µes)
      - Dificuldade m√©dia das quest√µes acertadas
      - Evolu√ß√£o ao longo do tempo
      """
      with self.db.get_session() as session:
          # Buscar √∫ltimas 20 quest√µes
          results = session.execute(
              text("""
                  SELECT
                      CASE WHEN r.alternativa_escolhida = g.alternativa_correta
                           THEN 1 ELSE 0 END as acertou,
                      q.dificuldade_real
                  FROM resposta_questao r
                  JOIN questao_oab q ON r.questao_id = q.id
                  JOIN gabarito_questao g ON q.id = g.questao_id
                  WHERE r.usuario_id = :usuario_id
                  ORDER BY r.timestamp DESC
                  LIMIT 20
              """),
              {"usuario_id": usuario_id}
          ).fetchall()

          if not results:
              return 0.3  # Iniciante

          acertos = sum(r[0] for r in results)
          dificuldades = [r[1] for r in results if r[0] == 1]  # Apenas acertos

          taxa_acerto = acertos / len(results)
          dificuldade_media = sum(dificuldades) / len(dificuldades) if dificuldades else 0.3

          # N√≠vel = m√©dia ponderada
          nivel = (taxa_acerto * 0.6) + (dificuldade_media * 0.4)

          return min(1.0, max(0.0, nivel))


[B] SELECIONAR QUEST√ïES ADAPTATIVAS

  def selecionar_proxima_questao_adaptativa(
      self,
      usuario_id: UUID,
      area: Optional[str] = None
  ) -> UUID:
      """
      Seleciona pr√≥xima quest√£o adaptada ao n√≠vel do usu√°rio.

      Estrat√©gia:
      - 70% das quest√µes no n√≠vel do usu√°rio (¬±0.1)
      - 20% ligeiramente mais dif√≠ceis (+0.1 a +0.2)
      - 10% ligeiramente mais f√°ceis (-0.1 a -0.2)
      """
      nivel = self.calcular_nivel_usuario(usuario_id)

      # Escolher faixa de dificuldade
      import random
      roll = random.random()

      if roll < 0.70:
          # N√≠vel atual
          dif_min, dif_max = nivel - 0.1, nivel + 0.1
      elif roll < 0.90:
          # Desafio
          dif_min, dif_max = nivel + 0.1, nivel + 0.2
      else:
          # Revis√£o
          dif_min, dif_max = nivel - 0.2, nivel - 0.1

      # Ajustar limites
      dif_min = max(0.0, dif_min)
      dif_max = min(1.0, dif_max)

      # Buscar quest√µes
      with self.db.get_session() as session:
          query = """
              SELECT q.id
              FROM questao_oab q
              LEFT JOIN resposta_questao r
                  ON q.id = r.questao_id AND r.usuario_id = :usuario_id
              WHERE q.dificuldade_real BETWEEN :dif_min AND :dif_max
                AND r.id IS NULL  -- Nunca respondida
          """

          params = {
              "usuario_id": usuario_id,
              "dif_min": float(dif_min),
              "dif_max": float(dif_max)
          }

          if area:
              query += " AND q.area = :area"
              params["area"] = area

          query += " ORDER BY RANDOM() LIMIT 1"

          result = session.execute(text(query), params).fetchone()

          return result[0] if result else None

GANHO PEDAG√ìGICO:
  - Zona de desenvolvimento proximal (Vygotsky)
  - Engajamento mantido (flow state)
  - Progress√£o gradual e consistente


================================================================================
3. MELHORIAS DE PERFORMANCE
================================================================================

3.1. SISTEMA DE CACHING
------------------------

[A] REDIS PARA CACHE

docker-compose.yml:

  services:
    redis:
      image: redis:7-alpine
      ports:
        - "6379:6379"
      volumes:
        - redis_data:/data

Depend√™ncia:
  pip install redis

Cache service:

  from redis import Redis
  import json

  class CacheService:
      def __init__(self):
          self.redis = Redis(
              host=os.getenv("REDIS_HOST", "localhost"),
              port=6379,
              decode_responses=True
          )

      def get_questao(self, questao_id: UUID) -> Optional[Dict]:
          """Busca quest√£o no cache."""
          key = f"questao:{questao_id}"
          data = self.redis.get(key)
          return json.loads(data) if data else None

      def set_questao(self, questao_id: UUID, questao: Dict, ttl: int = 3600):
          """Salva quest√£o no cache (1 hora padr√£o)."""
          key = f"questao:{questao_id}"
          self.redis.setex(key, ttl, json.dumps(questao))

      def invalidate_questao(self, questao_id: UUID):
          """Invalida cache de quest√£o."""
          key = f"questao:{questao_id}"
          self.redis.delete(key)

APLICA√á√ÉO:
  - Cache de quest√µes (raramente mudam): TTL 24h
  - Cache de normas (nunca mudam): TTL 7 dias
  - Cache de m√©tricas agregadas: TTL 1 hora
  - Cache de explica√ß√µes: TTL indefinido

GANHO:
  - Tempo de resposta: 200ms ‚Üí 20ms (10x)
  - Redu√ß√£o de carga no PostgreSQL: 70%


[B] QUERY CACHING NO POSTGRESQL

  ALTER TABLE questao_oab SET (autovacuum_enabled = true);
  ANALYZE questao_oab;

  -- Shared buffers (25% da RAM)
  shared_buffers = 4GB
  effective_cache_size = 12GB
  work_mem = 64MB


3.2. OTIMIZA√á√ÉO DE QUERIES
---------------------------

[A] MATERIALIZAR VIEWS PESADAS

  CREATE MATERIALIZED VIEW mv_estatisticas_usuario AS
  SELECT
      usuario_id,
      COUNT(*) as total_questoes,
      SUM(CASE WHEN acertou THEN 1 ELSE 0 END) as total_acertos,
      AVG(CASE WHEN acertou THEN 1.0 ELSE 0.0 END) as taxa_acerto,
      MAX(timestamp) as ultima_atividade
  FROM resposta_questao
  GROUP BY usuario_id;

  CREATE UNIQUE INDEX idx_mv_estatisticas_usuario ON mv_estatisticas_usuario(usuario_id);

  -- Refresh di√°rio
  REFRESH MATERIALIZED VIEW CONCURRENTLY mv_estatisticas_usuario;

GANHO:
  - Query de dashboard: 5s ‚Üí 50ms (100x)


[B] √çNDICES COMPOSTOS

  -- Para busca comum: √°rea + dificuldade + n√£o respondida
  CREATE INDEX idx_questao_oab_area_dificuldade
  ON questao_oab(area, dificuldade_real)
  WHERE ativo = TRUE;

  -- Para revis√µes pendentes
  CREATE INDEX idx_revisao_proxima_usuario
  ON revisao_espacada(usuario_id, proxima_revisao)
  WHERE proxima_revisao <= CURRENT_DATE;


================================================================================
4. MELHORIAS DE EXPERI√äNCIA DO USU√ÅRIO
================================================================================

4.1. GAMIFICATION
-----------------

[A] SISTEMA DE PONTOS E XP

Tabela:

  CREATE TABLE pontuacao_usuario (
      id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
      usuario_id UUID NOT NULL REFERENCES usuario(id),

      -- Pontos
      xp_total INTEGER DEFAULT 0,
      nivel INTEGER DEFAULT 1,
      xp_para_proximo_nivel INTEGER DEFAULT 100,

      -- Streaks
      dias_consecutivos INTEGER DEFAULT 0,
      melhor_streak INTEGER DEFAULT 0,
      ultima_atividade DATE,

      -- Conquistas
      conquistas JSONB DEFAULT '[]'::jsonb,

      -- Ranking
      posicao_ranking INTEGER,

      updated_at TIMESTAMP DEFAULT NOW()
  );

Regras de XP:
  - Quest√£o correta: 10 XP √ó multiplicador de dificuldade
  - Quest√£o incorreta: 2 XP (participa√ß√£o)
  - Sess√£o completa: 50 XP b√¥nus
  - Streak de 7 dias: 100 XP b√¥nus
  - Revis√£o espacada: 15 XP


[B] CONQUISTAS (ACHIEVEMENTS)

  const CONQUISTAS = {
      "primeira_questao": {
          "titulo": "Primeiros Passos",
          "descricao": "Responda sua primeira quest√£o",
          "xp_bonus": 50
      },
      "streak_7": {
          "titulo": "Disciplinado",
          "descricao": "Estude 7 dias consecutivos",
          "xp_bonus": 200
      },
      "taxa_acerto_80": {
          "titulo": "Expert",
          "descricao": "Alcance 80% de acerto em uma √°rea",
          "xp_bonus": 500
      },
      "100_questoes": {
          "titulo": "Centen√°rio",
          "descricao": "Responda 100 quest√µes",
          "xp_bonus": 300
      },
      "dominar_area": {
          "titulo": "Mestre em [√Årea]",
          "descricao": "Acerte 90% das quest√µes de uma √°rea",
          "xp_bonus": 1000
      }
  };


[C] LEADERBOARD

  GET /ranking

  RESPONSE:
  {
      "minha_posicao": 12,
      "meu_xp": 2340,
      "top_10": [
          {
              "posicao": 1,
              "nome": "Ana S.",  // Anonimizado
              "xp": 5670,
              "nivel": 15
          }
      ],
      "ranking_amigos": [...]  // Se feature social habilitada
  }

GANHO:
  - Reten√ß√£o aumenta 40%
  - Engajamento di√°rio aumenta 60%


4.2. FEEDBACK VISUAL
--------------------

[A] PROGRESS TRACKING POR √ÅREA

  GET /progresso/areas

  RESPONSE:
  {
      "areas": [
          {
              "nome": "Direito Penal",
              "questoes_respondidas": 45,
              "questoes_totais": 120,
              "taxa_acerto": 0.67,
              "nivel_dominio": "intermediario",  // iniciante, intermediario, avancado, expert
              "proxima_revisao": 8,
              "recomendacao": "Foque em crimes contra a honra (50% de erro)"
          }
      ],
      "progresso_geral": 0.38  // 38% do conte√∫do OAB coberto
  }


[B] MAPA DE CALOR DE CONHECIMENTO

Visualiza√ß√£o de √°reas fortes/fracas:

  {
      "mapa_conhecimento": {
          "Direito Constitucional": {
              "Direitos Fundamentais": 0.85,  // Verde escuro
              "Organiza√ß√£o do Estado": 0.45,  // Amarelo
              "Controle de Constitucionalidade": 0.20  // Vermelho
          },
          "Direito Penal": {...}
      }
  }


================================================================================
5. ANALYTICS PREDITIVOS
================================================================================

5.1. PREDI√á√ÉO DE APROVA√á√ÉO
---------------------------

[A] MODELO DE MACHINE LEARNING

Criar: ml/predicao_aprovacao.py

  from sklearn.ensemble import RandomForestClassifier
  import numpy as np

  class PredicaoAprovacao:
      def __init__(self):
          self.model = RandomForestClassifier(n_estimators=100)

      def treinar_modelo(self):
          """
          Treina modelo com dados hist√≥ricos de aprovados/reprovados.

          Features:
          - Taxa de acerto por √°rea (14 features)
          - Total de quest√µes respondidas
          - Dias de estudo
          - Streak m√°ximo
          - Taxa de revis√µes completas
          - Dificuldade m√©dia das quest√µes acertadas
          - Tempo m√©dio por quest√£o
          - Distribui√ß√£o de erros por tipo
          """
          # Buscar dados hist√≥ricos (se dispon√≠veis)
          X_train, y_train = self._preparar_dados_treino()

          self.model.fit(X_train, y_train)

      def prever_aprovacao(self, usuario_id: UUID) -> Dict:
          """
          Prev√™ probabilidade de aprova√ß√£o.

          Returns:
              {
                  "probabilidade_aprovacao": 0.72,
                  "confianca": 0.85,
                  "principais_fatores": [
                      {"fator": "Taxa de acerto em Penal", "impacto": 0.25},
                      {"fator": "Dias de estudo", "impacto": 0.18}
                  ],
                  "areas_melhorar": ["Direito Tribut√°rio", "Empresarial"]
              }
          """
          features = self._extrair_features(usuario_id)
          proba = self.model.predict_proba([features])[0][1]

          # Feature importance
          importances = self.model.feature_importances_
          fatores = self._interpretar_importances(importances, features)

          return {
              "probabilidade_aprovacao": float(proba),
              "confianca": self._calcular_confianca(features),
              "principais_fatores": fatores,
              "areas_melhorar": self._identificar_gaps(usuario_id)
          }

EXIBI√á√ÉO AO USU√ÅRIO:
  - Dashboard: "Sua probabilidade de aprova√ß√£o: 72%"
  - Recomenda√ß√µes personalizadas
  - Plano de estudos otimizado


================================================================================
6. PRIORIZA√á√ÉO DE IMPLEMENTA√á√ÉO
================================================================================

6.1. CRITICIDADE vs ESFOR√áO
----------------------------

ALTA PRIORIDADE (Implementar IMEDIATAMENTE):

  üî¥ P0: Sistema de cache (Redis)
       Esfor√ßo: 1 dia
       Impacto: Performance 10x melhor

  üî¥ P0: Explica√ß√µes com LLM
       Esfor√ßo: 2 dias
       Impacto: Efic√°cia pedag√≥gica 3x maior

  üî¥ P0: Gera√ß√£o de embeddings
       Esfor√ßo: 1 dia
       Impacto: Busca sem√¢ntica habilitada

M√âDIA PRIORIDADE (Implementar ap√≥s go-live est√°vel):

  üü° P1: Spaced repetition
       Esfor√ßo: 3 dias
       Impacto: Reten√ß√£o +50%

  üü° P1: Adaptive learning
       Esfor√ßo: 2 dias
       Impacto: Engajamento +40%

  üü° P1: Gamification b√°sica (XP + conquistas)
       Esfor√ßo: 2 dias
       Impacto: Reten√ß√£o +30%

BAIXA PRIORIDADE (Futuro):

  üü¢ P2: Analytics preditivos (ML)
       Esfor√ßo: 5 dias
       Impacto: Diferencia√ß√£o competitiva

  üü¢ P2: Leaderboard social
       Esfor√ßo: 2 dias
       Impacto: Engajamento +20%


6.2. ROADMAP SUGERIDO
----------------------

SPRINT 1 (Semana 1-2): Performance
  - Implementar Redis cache
  - Otimizar queries cr√≠ticas
  - √çndices compostos

SPRINT 2 (Semana 3-4): Pedagogia
  - Gerar embeddings
  - Integrar LLM para explica√ß√µes
  - Busca sem√¢ntica

SPRINT 3 (Semana 5-6): Reten√ß√£o
  - Spaced repetition
  - Adaptive learning
  - Progress tracking visual

SPRINT 4 (Semana 7-8): Engajamento
  - Sistema de XP
  - Conquistas
  - Streaks

SPRINT 5+ (Futuro):
  - Analytics preditivos
  - Social features
  - Conte√∫do adicional


================================================================================
7. CONCLUS√ÉO
================================================================================

PRINCIPAIS MELHORIAS RECOMENDADAS:

‚úÖ CR√çTICAS (Implementar agora):
   1. Redis cache ‚Üí Performance 10x
   2. LLM explica√ß√µes ‚Üí Aprendizado 3x melhor
   3. Embeddings ‚Üí Busca sem√¢ntica habilitada

‚úÖ IMPORTANTES (Pr√≥ximo m√™s):
   4. Spaced repetition ‚Üí Reten√ß√£o +50%
   5. Adaptive learning ‚Üí Engajamento +40%
   6. Gamification ‚Üí Reten√ß√£o +30%

‚úÖ DIFERENCIAIS (Futuro):
   7. ML predi√ß√£o ‚Üí Diferencia√ß√£o competitiva
   8. Social features ‚Üí Viralidade

IMPACTO ESTIMADO (ap√≥s implementa√ß√£o completa):
  - Performance: 10x mais r√°pido
  - Efic√°cia pedag√≥gica: 3x maior
  - Reten√ß√£o de usu√°rios: +70%
  - Probabilidade de aprova√ß√£o: +25%

CUSTO ADICIONAL MENSAL:
  - OpenAI (explica√ß√µes + embeddings): ~$50/m√™s
  - Redis hosting: ~$15/m√™s (Upstash/Redis Cloud)
  - TOTAL: ~$65/m√™s para 100 usu√°rios

ROI: ALT√çSSIMO (custo $0.65/usu√°rio para 3x melhor resultado)

================================================================================
FIM DA AN√ÅLISE
================================================================================
